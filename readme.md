<img src="icon.png" align="right" />

# 66 Days of Data Challenge

This repo includes projects that I did during this challenge. 

## Brief Project Descriptions

- [Translating SQL to Pandas](https://github.com/asad-mahmood/66DaysOfData/tree/main/SQL%20to%20Pandas) - A small project that I used to perpare for interviews where questions regarding translating SQL statements to pandas or vice versa were expected. It walks through how all the major keywords of SQL can be successfully translated to pandas statements.
- [Data Preprocessing and ML Template](https://github.com/asad-mahmood/66DaysOfData/tree/main/Data%20Preprocessing%20and%20ML%20Template) - A preprocessing template that I use for every project classification/regression to start with. I am using lazy predict package to test out which algo is the best suited for the project.
- [Fake News Detection](https://github.com/asad-mahmood/66DaysOfData/tree/main/Fake%20News%20Detection) - This project is about how to use tweets text and classify them. In this cproblem statement is to classify if the suggested tweets contain misinformation or not. The classification model used is Passive Aggressive Classfier and achieved 92 % accuracy score and 585 true positives, 590 true negatives, 48 false positives, and 44 false negatives.
- [Heart Attack Detection](https://github.com/asad-mahmood/66DaysOfData/tree/main/Heart%20Failure) - The main objective of this project is to build an effective classification model to predict heart attack based on underlying factors. I felt some features were not as important as others so I used Extra Trees Classifier and Step forward and backward feature selection methods to determine the most important features. After that I chose the top three and standaerdized them and used LazyPredict library to determine which algos will be best for making an effective model. I chose the top two i.e Extra Trees Classifier and Decision Trees Classfier. I fine tuned them and in the end Extra Trees Classifier won because of its higher accuracy rate of 92 % compared to Decision Trees 88 %. Along with that it also had a better sensitivity and specificty rate.
